{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_a1q4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOuDku5Axf7TBea3ZLQdoAB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wtiVBoawDks",
        "colab_type": "text"
      },
      "source": [
        "Rading text from files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkVIgXclToJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwJ4-TCCUK7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query = open('d_query.txt').read()\n",
        "d1 = open('d1.txt').read()\n",
        "d2 = open('d2.txt').read()\n",
        "d3 = open('d3.txt').read()\n",
        "d4 = open('d4.txt').read()\n",
        "d5 = open('d5.txt').read()\n",
        "\n",
        "\n",
        "vocab = d1 + d2+ d3+ d4+ d5\n",
        "print(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs_ZZH9bwjkL",
        "colab_type": "text"
      },
      "source": [
        "Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsLFC0iozWm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "import os\n",
        "import string\n",
        "import numpy as np\n",
        "import copy\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbSiC-fOzBab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stop_words(data):\n",
        "    stop_words = stopwords.words('english')\n",
        "    words = word_tokenize(str(data))\n",
        "    new_text = \"\"\n",
        "    for w in words:\n",
        "        if w not in stop_words and len(w) > 1:\n",
        "            new_text = new_text + \" \" + w\n",
        "    return new_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8RYqP5-zHG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuation(data):\n",
        "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
        "    for i in range(len(symbols)):\n",
        "        data = np.char.replace(data, symbols[i], ' ')\n",
        "        data = np.char.replace(data, \"  \", \" \")\n",
        "    data = np.char.replace(data, ',', '')\n",
        "    data = np.char.replace(data, '\\\"', '')\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgExlxuuzIXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_apostrophe(data):\n",
        "    return np.char.replace(data, \"'\", \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klGBKA4RzK2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(data):\n",
        "    data = convert_lower_case(data)\n",
        "    data = remove_punctuation(data) #remove comma seperately\n",
        "    data = remove_apostrophe(data) \n",
        "    data = remove_stop_words(data)\n",
        "    data = remove_punctuation(data)\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N39mRmqczO57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_lower_case(data):\n",
        "    return np.char.lower(data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn-V35qc0FVF",
        "colab_type": "code",
        "outputId": "afdc43d3-26d1-4289-c765-6f9fd8d27dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> punkt\n",
            "    Downloading package punkt to /root/nltk_data...\n",
            "      Unzipping tokenizers/punkt.zip.\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggKyvuxKx4vf",
        "colab_type": "code",
        "outputId": "fcdb3105-42bf-400d-fffb-179686c023c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "processed_text = [] \n",
        "processed_text.append(word_tokenize(str(preprocess(d1))))\n",
        "processed_text.append(word_tokenize(str(preprocess(d2))))\n",
        "processed_text.append(word_tokenize(str(preprocess(d3))))\n",
        "processed_text.append(word_tokenize(str(preprocess(d4))))\n",
        "processed_text.append(word_tokenize(str(preprocess(d5))))\n",
        "processed_text.append(word_tokenize(str(preprocess(query))))\n",
        "\n",
        "d_query_tokens = [] \n",
        "d_query_tokens = word_tokenize(str(preprocess(query)))\n",
        "print(d_query_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['java', 'coffee', 'mocha']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1bqPY-P1FbL",
        "colab_type": "text"
      },
      "source": [
        "Counting frequencies of each word in the whole data set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSv4EYz-1ITh",
        "colab_type": "code",
        "outputId": "adecb5eb-06b8-47f7-88ce-168a4a069ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# processed_text\n",
        "N = len (processed_text)\n",
        "df = {}\n",
        "\n",
        "for i in range(N):\n",
        "    tokens = processed_text[i]\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            df[word].add(i)\n",
        "        except:\n",
        "            df[word] = {i}\n",
        "    \n",
        "for i in df:\n",
        "    df[i] = len(df[i])\n",
        "\n",
        "total_vocab_size = len(df)\n",
        "print(total_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9jQuzIi2qhI",
        "colab_type": "text"
      },
      "source": [
        "Compute tf-idf values for each word in every document as well as the query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FiWyE262qG_",
        "colab_type": "code",
        "outputId": "46dac639-3a07-40ae-ced2-33ee8b229e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "def compute_tf_idf(word_vocab, document_text,DF_freq):\n",
        "    tf_idf = {} \n",
        "    N = 4\n",
        "    tokens = document_text    \n",
        "    counter = Counter(tokens)\n",
        "    words_count = len(tokens)\n",
        "\n",
        "    for token in np.unique(tokens):\n",
        "        tf = counter[token]/words_count\n",
        "        df = DF_freq[token]\n",
        "        idf = np.log((N+1)/(df+1))\n",
        "        tf_idf[token] = tf*idf\n",
        "        \n",
        "    return tf_idf\n",
        "\n",
        "\n",
        "total_vocab = [x for x in df]\n",
        "\n",
        "d1_tf_idf = compute_tf_idf(total_vocab,processed_text[0],df)\n",
        "d2_tf_idf = compute_tf_idf(total_vocab,processed_text[1],df)\n",
        "d3_tf_idf = compute_tf_idf(total_vocab,processed_text[2],df)\n",
        "d4_tf_idf = compute_tf_idf(total_vocab,processed_text[3],df)\n",
        "d5_tf_idf = compute_tf_idf(total_vocab,processed_text[4],df)\n",
        "print(d1_tf_idf)\n",
        "print(d2_tf_idf)\n",
        "print(d3_tf_idf)\n",
        "print(d4_tf_idf)\n",
        "print(d5_tf_idf)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'141': 0.009072185464100546, '56': 0.009072185464100546, '60': 0.009072185464100546, 'along': 0.009072185464100546, 'beliefs': 0.009072185464100546, 'bilingual': 0.009072185464100546, 'buddhist': 0.009072185464100546, 'capital': 0.009072185464100546, 'center': 0.005057679443227631, 'chain': 0.009072185464100546, 'city': 0.009072185464100546, 'colonial': 0.009072185464100546, 'core': 0.005057679443227631, 'cultures': 0.009072185464100546, 'diverse': 0.009072185464100546, 'dominant': 0.009072185464100546, 'dutch': 0.005057679443227631, 'earth': 0.009072185464100546, 'east': 0.009072185464100546, 'eastâ€“west': 0.009072185464100546, 'empires': 0.009072185464100546, 'eruptions': 0.009072185464100546, 'ethnicities': 0.009072185464100546, 'fifth': 0.009072185464100546, 'first': 0.009072185464100546, 'formed': 0.009072185464100546, 'forms': 0.009072185464100546, 'furthermore': 0.009072185464100546, 'hindu': 0.009072185464100546, 'history': 0.009072185464100546, 'home': 0.005057679443227631, 'indies': 0.009072185464100546, 'indonesia': 0.036288741856402185, 'indonesian': 0.020230717772910523, 'islamic': 0.009072185464100546, 'island': 0.011046710461099493, 'jakarta': 0.009072185464100546, 'java': -0.026651266267026765, 'javanese': 0.018144370928201092, 'language': 0.015173038329682892, 'languages': 0.005057679443227631, 'largest': 0.004418684184439798, 'live': 0.009072185464100546, 'located': 0.005057679443227631, 'madurese': 0.009072185464100546, 'main': 0.005057679443227631, 'majority': 0.009072185464100546, 'million': 0.010115358886455261, 'mixture': 0.009072185464100546, 'mostly': 0.009072185464100546, 'mountains': 0.009072185464100546, 'much': 0.005057679443227631, 'muslim': 0.009072185464100546, 'native': 0.009072185464100546, 'official': 0.005057679443227631, 'people': 0.010115358886455261, 'percent': 0.009072185464100546, 'place': 0.009072185464100546, 'population': 0.018144370928201092, 'populous': 0.009072185464100546, 'powerful': 0.009072185464100546, 'religious': 0.009072185464100546, 'residents': 0.009072185464100546, 'result': 0.009072185464100546, 'second': 0.002209342092219899, 'speaking': 0.009072185464100546, 'spine': 0.009072185464100546, 'spoken': 0.009072185464100546, 'sultanates': 0.009072185464100546, 'sundanese': 0.009072185464100546, 'thirteenth': 0.009072185464100546, 'three': 0.009072185464100546, 'took': 0.009072185464100546, 'volcanic': 0.018144370928201092, 'western': 0.009072185464100546, 'world': 0.009072185464100546}\n",
            "{'1040': 0.006994585739497367, '15': 0.006994585739497367, '1500': 0.006994585739497367, '2007': 0.0038994322424884785, '2008': 0.006994585739497367, '2010': 0.006994585739497367, '26': 0.006994585739497367, '3412': 0.006994585739497367, 'according': 0.013989171478994734, 'accused': 0.006994585739497367, 'administrative': 0.013989171478994734, 'announced': 0.006994585739497367, 'approximately': 0.006994585739497367, 'area': 0.006994585739497367, 'assembly': 0.006994585739497367, 'attention': 0.006994585739497367, 'base': 0.006994585739497367, 'bases': 0.006994585739497367, 'battle': 0.006994585739497367, 'boundaries': 0.006994585739497367, 'brought': 0.006994585739497367, 'building': 0.006994585739497367, 'caucasus': 0.006994585739497367, 'center': 0.0038994322424884785, 'co': 0.006994585739497367, 'concerns': 0.006994585739497367, 'conflict': 0.006994585739497367, 'constructing': 0.006994585739497367, 'current': 0.006994585739497367, 'defined': 0.006994585739497367, 'district': 0.013989171478994734, 'division': 0.006994585739497367, 'dzau': 0.013989171478994734, 'europe': 0.006994585739497367, 'forces': 0.006994585739497367, 'ft': 0.006994585739497367, 'general': 0.001703385887894731, 'georgia': 0.0209837572184921, 'georgian': 0.013989171478994734, 'georgias': 0.006994585739497367, 'gorge': 0.006994585739497367, 'government': 0.0038994322424884785, 'greater': 0.013989171478994734, 'java': -0.01797943249120985, 'kartli': 0.006994585739497367, 'km': 0.006994585739497367, 'large': 0.0038994322424884785, 'largest': 0.001703385887894731, 'level': 0.0038994322424884785, 'liakhvi': 0.006994585739497367, 'located': 0.007798864484976957, 'main': 0.0038994322424884785, 'major': 0.006994585739497367, 'mikheil': 0.006994585739497367, 'military': 0.02797834295798947, 'north': 0.006994585739497367, 'offensive': 0.006994585739497367, 'official': 0.0038994322424884785, 'operation': 0.006994585739497367, 'organization': 0.006994585739497367, 'ossetia': 0.02797834295798947, 'ossetian': 0.0209837572184921, 'outside': 0.006994585739497367, 'people': 0.0038994322424884785, 'played': 0.006994585739497367, 'president': 0.006994585739497367, 'radius': 0.006994585739497367, 'ready': 0.006994585739497367, 'region': 0.006994585739497367, 'relocated': 0.006994585739497367, 'role': 0.006994585739497367, 'russia': 0.006994585739497367, 'russian': 0.006994585739497367, 'saakashvili': 0.006994585739497367, 'sea': 0.0038994322424884785, 'second': 0.001703385887894731, 'security': 0.006994585739497367, 'september': 0.006994585739497367, 'settlement': 0.006994585739497367, 'shida': 0.006994585739497367, 'side': 0.006994585739497367, 'situated': 0.006994585739497367, 'slopes': 0.006994585739497367, 'south': 0.0419675144369842, 'southern': 0.006994585739497367, 'time': 0.006994585739497367, 'town': 0.02797834295798947, 'tskhinvali': 0.02797834295798947, 'un': 0.006994585739497367, 'urban': 0.006994585739497367, 'war': 0.011698296727465436, 'within': 0.013989171478994734, 'would': 0.006994585739497367, 'zone': 0.006994585739497367}\n",
            "{'1812': 0.010014106359280383, '1814': 0.005007053179640192, '1815': 0.010014106359280383, '1816': 0.005007053179640192, '1817': 0.005007053179640192, '1827': 0.005007053179640192, '1831': 0.005007053179640192, '1842': 0.005007053179640192, '22': 0.005007053179640192, '29': 0.005007053179640192, '44': 0.005007053179640192, 'active': 0.005007053179640192, 'algiers': 0.010014106359280383, 'american': 0.010014106359280383, 'april': 0.005007053179640192, 'ashore': 0.005007053179640192, 'august': 0.005007053179640192, 'bainbridge': 0.005007053179640192, 'baltimore': 0.010014106359280383, 'barbary': 0.005007053179640192, 'bearing': 0.005007053179640192, 'became': 0.005007053179640192, 'biddle': 0.005007053179640192, 'bitter': 0.005007053179640192, 'boston': 0.005007053179640192, 'brazil': 0.005007053179640192, 'broken': 0.005007053179640192, 'built': 0.002791396851180277, 'burned': 0.005007053179640192, 'captain': 0.015021159538920576, 'captured': 0.005007053179640192, 'citizens': 0.005007053179640192, 'coast': 0.005007053179640192, 'command': 0.010014106359280383, 'commerce': 0.005007053179640192, 'commodore': 0.005007053179640192, 'completed': 0.005007053179640192, 'constellation': 0.005007053179640192, 'constitution': 0.005007053179640192, 'crane': 0.005007053179640192, 'crew': 0.005007053179640192, 'cruise': 0.010014106359280383, 'damage': 0.005007053179640192, 'december': 0.005007053179640192, 'departed': 0.005007053179640192, 'deployment': 0.005007053179640192, 'dey': 0.005007053179640192, 'diplomatic': 0.005007053179640192, 'duties': 0.005007053179640192, 'early': 0.005007053179640192, 'end': 0.010014106359280383, 'engagement': 0.005007053179640192, 'erie': 0.005007053179640192, 'face': 0.005007053179640192, 'far': 0.005007053179640192, 'fill': 0.005007053179640192, 'five': 0.002791396851180277, 'flag': 0.005007053179640192, 'flagship': 0.005007053179640192, 'flannigan': 0.005007053179640192, 'frigate': 0.015021159538920576, 'gale': 0.005007053179640192, 'gibraltar': 0.005007053179640192, 'got': 0.005007053179640192, 'guns': 0.005007053179640192, 'hampton': 0.005007053179640192, 'hazard': 0.005007053179640192, 'hms': 0.010014106359280383, 'home': 0.002791396851180277, 'honor': 0.005007053179640192, 'hulled': 0.005007053179640192, 'ignoring': 0.005007053179640192, 'island': 0.0012193636683836598, 'james': 0.002791396851180277, 'january': 0.005007053179640192, 'java': -0.014709168814042094, 'killing': 0.005007053179640192, 'laid': 0.005007053179640192, 'maryland': 0.005007053179640192, 'massachusetts': 0.005007053179640192, 'masts': 0.005007053179640192, 'mediterranean': 0.015021159538920576, 'men': 0.005007053179640192, 'messina': 0.005007053179640192, 'named': 0.005007053179640192, 'naples': 0.005007053179640192, 'navy': 0.005007053179640192, 'new': 0.010014106359280383, 'newport': 0.015021159538920576, 'next': 0.005007053179640192, 'norfolk': 0.005007053179640192, 'oliver': 0.005007053179640192, 'one': 0.0012193636683836598, 'ontario': 0.005007053179640192, 'ordered': 0.010014106359280383, 'palermo': 0.005007053179640192, 'parsons': 0.005007053179640192, 'performed': 0.005007053179640192, 'perry': 0.010014106359280383, 'persuaded': 0.005007053179640192, 'picked': 0.005007053179640192, 'port': 0.005007053179640192, 'previous': 0.005007053179640192, 'protected': 0.005007053179640192, 'receiving': 0.005007053179640192, 'resolve': 0.005007053179640192, 'returned': 0.010014106359280383, 'returning': 0.005007053179640192, 'rhode': 0.005007053179640192, 'rigging': 0.005007053179640192, 'roads': 0.005007053179640192, 'sailed': 0.010014106359280383, 'sailing': 0.005007053179640192, 'sea': 0.002791396851180277, 'second': 0.0024387273367673197, 'serve': 0.005007053179640192, 'served': 0.005007053179640192, 'service': 0.005007053179640192, 'severe': 0.005007053179640192, 'ship': 0.005007053179640192, 'show': 0.005007053179640192, 'signed': 0.005007053179640192, 'snapped': 0.005007053179640192, 'spare': 0.005007053179640192, 'states': 0.015021159538920576, 'stopping': 0.005007053179640192, 'strength': 0.002791396851180277, 'suffered': 0.005007053179640192, 'summer': 0.005007053179640192, 'syracuse': 0.005007053179640192, 'ten': 0.005007053179640192, 'toward': 0.005007053179640192, 'treaty': 0.005007053179640192, 'tripoli': 0.005007053179640192, 'truce': 0.005007053179640192, 'tunis': 0.005007053179640192, 'underway': 0.005007053179640192, 'united': 0.015021159538920576, 'upon': 0.005007053179640192, 'uss': 0.005007053179640192, 'victory': 0.005007053179640192, 'war': 0.005582793702360554, 'went': 0.005007053179640192, 'william': 0.010014106359280383, 'wooden': 0.005007053179640192, 'yards': 0.005007053179640192, 'york': 0.005007053179640192}\n",
            "{'18th': 0.005911553108865517, '4000': 0.005911553108865517, 'acidity': 0.005911553108865517, 'age': 0.011823106217731034, 'aged': 0.011823106217731034, 'aired': 0.005911553108865517, 'almost': 0.005911553108865517, 'also': 0.003295649185587037, 'beans': 0.011823106217731034, 'belawan': 0.005911553108865517, 'best': 0.005911553108865517, 'black': 0.005911553108865517, 'blauan': 0.005911553108865517, 'blawan': 0.005911553108865517, 'blend': 0.005911553108865517, 'body': 0.011823106217731034, 'brown': 0.011823106217731034, 'built': 0.003295649185587037, 'burlap': 0.005911553108865517, 'called': 0.005911553108865517, 'cedar': 0.005911553108865517, 'century': 0.005911553108865517, 'certain': 0.005911553108865517, 'cherries': 0.005911553108865517, 'cinnamon': 0.005911553108865517, 'clove': 0.005911553108865517, 'coffee': 0.032956491855870365, 'coffees': 0.011823106217731034, 'component': 0.003295649185587037, 'control': 0.005911553108865517, 'countries': 0.005911553108865517, 'cover': 0.005911553108865517, 'develop': 0.005911553108865517, 'display': 0.011823106217731034, 'distinguish': 0.005911553108865517, 'djampit': 0.005911553108865517, 'dusted': 0.005911553108865517, 'dutch': 0.003295649185587037, 'estates': 0.02364621243546207, 'fermented': 0.005911553108865517, 'finish': 0.005911553108865517, 'five': 0.006591298371174074, 'flavor': 0.011823106217731034, 'flavors': 0.005911553108865517, 'flipped': 0.005911553108865517, 'gains': 0.005911553108865517, 'general': 0.0014396358149303856, 'good': 0.005911553108865517, 'government': 0.003295649185587037, 'green': 0.005911553108865517, 'grown': 0.005911553108865517, 'harvest': 0.005911553108865517, 'heavy': 0.005911553108865517, 'hectares': 0.005911553108865517, 'herbaceous': 0.005911553108865517, 'impression': 0.005911553108865517, 'indonesian': 0.006591298371174074, 'island': 0.0014396358149303856, 'jampit': 0.005911553108865517, 'java': -0.015195520363538646, 'kayumas': 0.005911553108865517, 'kopi': 0.005911553108865517, 'large': 0.006591298371174074, 'largest': 0.0014396358149303856, 'lasting': 0.005911553108865517, 'light': 0.005911553108865517, 'losing': 0.005911553108865517, 'mills': 0.005911553108865517, 'mocca': 0.005911553108865517, 'normally': 0.005911553108865517, 'note': 0.005911553108865517, 'often': 0.005911553108865517, 'old': 0.01773465932659655, 'one': 0.0014396358149303856, 'origin': 0.005911553108865517, 'overall': 0.005911553108865517, 'pairs': 0.005911553108865517, 'pancoer': 0.005911553108865517, 'pancur': 0.005911553108865517, 'phrase': 0.005911553108865517, 'portion': 0.005911553108865517, 'primarily': 0.005911553108865517, 'prized': 0.005911553108865517, 'process': 0.003295649185587037, 'produced': 0.005911553108865517, 'profiles': 0.005911553108865517, 'pulp': 0.005911553108865517, 'quality': 0.005911553108865517, 'quickly': 0.005911553108865517, 'ranging': 0.005911553108865517, 'refer': 0.005911553108865517, 'refers': 0.011823106217731034, 'regularly': 0.005911553108865517, 'results': 0.005911553108865517, 'rigorous': 0.005911553108865517, 'ripe': 0.005911553108865517, 'rustic': 0.005911553108865517, 'sacks': 0.005911553108865517, 'smooth': 0.005911553108865517, 'sometimes': 0.011823106217731034, 'spelled': 0.005911553108865517, 'spices': 0.005911553108865517, 'strength': 0.003295649185587037, 'strong': 0.005911553108865517, 'style': 0.005911553108865517, 'subtle': 0.005911553108865517, 'supple': 0.005911553108865517, 'sweet': 0.011823106217731034, 'syrupy': 0.005911553108865517, 'taste': 0.005911553108865517, 'thick': 0.005911553108865517, 'traditional': 0.005911553108865517, 'transport': 0.005911553108865517, 'tugosari': 0.005911553108865517, 'turn': 0.005911553108865517, 'used': 0.005911553108865517, 'using': 0.005911553108865517, 'washed': 0.005911553108865517, 'wet': 0.005911553108865517, 'years': 0.005911553108865517, 'yemen': 0.005911553108865517}\n",
            "{'1995': 0.006498515828894717, '2007': 0.0036228767642978066, '2016': 0.006498515828894717, 'acquired': 0.006498515828894717, 'also': 0.0036228767642978066, 'alternative': 0.006498515828894717, 'anywhere': 0.006498515828894717, 'applets': 0.006498515828894717, 'application': 0.006498515828894717, 'applications': 0.012997031657789433, 'architecture': 0.006498515828894717, 'based': 0.006498515828894717, 'browser': 0.006498515828894717, 'bytecode': 0.012997031657789433, 'class': 0.012997031657789433, 'classpath': 0.006498515828894717, 'client': 0.006498515828894717, 'code': 0.006498515828894717, 'community': 0.006498515828894717, 'compiled': 0.012997031657789433, 'compiler': 0.012997031657789433, 'compilers': 0.006498515828894717, 'compliance': 0.006498515828894717, 'component': 0.0036228767642978066, 'computer': 0.012997031657789433, 'concurrent': 0.006498515828894717, 'core': 0.0036228767642978066, 'corporation': 0.006498515828894717, 'dependencies': 0.006498515828894717, 'derives': 0.006498515828894717, 'designed': 0.006498515828894717, 'developed': 0.012997031657789433, 'developers': 0.012997031657789433, 'either': 0.006498515828894717, 'facilities': 0.006498515828894717, 'fewer': 0.006498515828894717, 'general': 0.0031651567562299256, 'gnu': 0.01949554748668415, 'gosling': 0.006498515828894717, 'icedtea': 0.006498515828894717, 'implementation': 0.012997031657789433, 'implementations': 0.006498515828894717, 'intended': 0.006498515828894717, 'james': 0.0036228767642978066, 'java': -0.028635935031592587, 'jvm': 0.006498515828894717, 'language': 0.007245753528595613, 'languages': 0.0036228767642978066, 'let': 0.006498515828894717, 'level': 0.0036228767642978066, 'libraries': 0.012997031657789433, 'license': 0.006498515828894717, 'licenses': 0.006498515828894717, 'low': 0.006498515828894717, 'machine': 0.006498515828894717, 'machines': 0.006498515828894717, 'may': 0.006498515828894717, 'meaning': 0.006498515828894717, 'microsystems': 0.012997031657789433, 'million': 0.0036228767642978066, 'much': 0.0036228767642978066, 'need': 0.006498515828894717, 'object': 0.006498515828894717, 'one': 0.0015825783781149628, 'oracle': 0.006498515828894717, 'oriented': 0.006498515828894717, 'original': 0.006498515828894717, 'originally': 0.012997031657789433, 'others': 0.006498515828894717, 'particularly': 0.006498515828894717, 'platform': 0.006498515828894717, 'platforms': 0.006498515828894717, 'plugin': 0.006498515828894717, 'popular': 0.006498515828894717, 'possible': 0.006498515828894717, 'process': 0.0036228767642978066, 'programming': 0.012997031657789433, 'proprietary': 0.006498515828894717, 'public': 0.006498515828894717, 'purpose': 0.006498515828894717, 'recompilation': 0.006498515828894717, 'reference': 0.006498515828894717, 'regardless': 0.006498515828894717, 'released': 0.012997031657789433, 'relicensed': 0.006498515828894717, 'reported': 0.006498515828894717, 'run': 0.01949554748668415, 'server': 0.006498515828894717, 'since': 0.006498515828894717, 'specifically': 0.006498515828894717, 'specifications': 0.006498515828894717, 'standard': 0.006498515828894717, 'sun': 0.032492579144473586, 'support': 0.006498515828894717, 'syntax': 0.006498515828894717, 'technologies': 0.012997031657789433, 'typically': 0.006498515828894717, 'use': 0.006498515828894717, 'virtual': 0.012997031657789433, 'web': 0.012997031657789433, 'without': 0.006498515828894717, 'wora': 0.006498515828894717, 'write': 0.006498515828894717}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx2wwnvi4d85",
        "colab_type": "text"
      },
      "source": [
        "Compute the cosine similarity between tf-idf vectors of each document and the query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrLqcX_B4PEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(a, b):\n",
        "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
        "    return cos_sim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tuxUBJu62xe",
        "colab_type": "text"
      },
      "source": [
        "Vectorize tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRPLaLBo5C17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vect_tf_idf(tf_idf,total_vocab_size):\n",
        "    D = np.zeros((1, total_vocab_size))\n",
        "    for i in tf_idf:\n",
        "        try:\n",
        "            ind = total_vocab.index(i)\n",
        "            D[0][ind] = tf_idf[i]\n",
        "        except:\n",
        "            pass\n",
        "    return D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvA31HiB7Acj",
        "colab_type": "code",
        "outputId": "aef2cc20-cf40-42ad-f304-0b9028b67aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "\n",
        "D1 = vect_tf_idf(d1_tf_idf,total_vocab_size)\n",
        "D1 = np.append (D1, vect_tf_idf(d2_tf_idf,total_vocab_size),axis = 0)\n",
        "D1 = np.append (D1, vect_tf_idf(d3_tf_idf,total_vocab_size),axis = 0)\n",
        "D1 = np.append (D1, vect_tf_idf(d4_tf_idf,total_vocab_size),axis = 0)\n",
        "D1 = np.append (D1, vect_tf_idf(d5_tf_idf,total_vocab_size),axis = 0)\n",
        "print(D1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.02665127  0.01104671  0.03628874 ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.01797943  0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.01470917  0.00121936  0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.01519552  0.00143964  0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.02863594  0.          0.         ...  0.00649852  0.00649852\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGOh1FwN8Jso",
        "colab_type": "text"
      },
      "source": [
        "Finding tf-idf values for the query document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pUegqxZ8QSm",
        "colab_type": "code",
        "outputId": "8124223b-4ac2-4f76-c782-312f647e57f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def gen_vector(tokens):\n",
        "    Q = np.zeros((len(total_vocab)))\n",
        "    \n",
        "    counter = Counter(tokens)\n",
        "    words_count = len(tokens)\n",
        "    \n",
        "    for token in np.unique(tokens):\n",
        "        tf = counter[token]/words_count\n",
        "        df_new = df[token]\n",
        "        idf = math.log((N+1)/(df_new+1))\n",
        "        try:\n",
        "            ind = total_vocab.index(token)\n",
        "            Q[ind] = tf*idf\n",
        "        except:\n",
        "            pass\n",
        "    return Q\n",
        "\n",
        "D_query = gen_vector(d_query_tokens);\n",
        "print(D_query)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.28243262 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.41758766]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLXIbFqD_V7V",
        "colab_type": "code",
        "outputId": "c70d2369-214f-46b0-94bf-75a949b017e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "d_cosines = [] \n",
        "for d in D1:\n",
        "    d_cosines.append(cosine_similarity(D_query, d))\n",
        "\n",
        "print(d_cosines)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 0.0, 0.0, 0.218230197731997, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFbxpboe_rFR",
        "colab_type": "text"
      },
      "source": [
        "The fourth document D4 has the maximum similarity value"
      ]
    }
  ]
}
